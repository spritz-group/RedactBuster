{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import numpy as np\n",
    "from nltk import PunktSentenceTokenizer\n",
    "import re\n",
    "from collections import Counter\n",
    "import imblearn\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "\n",
    "df_path = 'dataset/echr/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 151836\n",
    "\n",
    "def setSeed(seed=seed):\n",
    "    \"\"\"\n",
    "    Setting the seed for reproducibility\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "setSeed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(split):\n",
    "    \n",
    "    df_split = split\n",
    "    annotation_file_path = f'{df_path}echr_{df_split}.json'\n",
    "\n",
    "    with open(annotation_file_path, 'r') as file:\n",
    "        annotations = json.load(file)\n",
    "\n",
    "    pst = PunktSentenceTokenizer()\n",
    "    sentences = []\n",
    "    set_sentences = set()\n",
    "    for i, element in enumerate(annotations):\n",
    "\n",
    "        text = element.get('text', None)\n",
    "        text = text.replace('(no. ','(no._') # change no. 1231 to no._1231\n",
    "        text = text.replace('(nos. ','(nos._')#when there is multiple number of case they use nos.\n",
    "        #the \"_\" after is to keep the number of chars constant without messing the tokenization\n",
    "        titles = re.findall('[^.]\\n\\n',text) #section titles don't have a dot at the end but \\n\\n, we search for those\n",
    "        for t in titles:                     # and replace with a dot and a space so they will be seen as a sentence and tokenized\n",
    "            text=text.replace(t,t[0]+'. ')\n",
    "        text = text.replace('\\n',' ') #if there are any \\n left we put spaces in their place to don't mess the char count\n",
    "\n",
    "    \n",
    "        element_sentences = pst.tokenize(text) \n",
    "        #tokenization messes up the index of characters because it deletes the \n",
    "        #spaces at the start of a sentence !!\n",
    "    \n",
    "        offsets = []\n",
    "        for annotator in element.get('annotations', None): \n",
    "            for ann in element['annotations'][annotator]['entity_mentions']:\n",
    "                offsets.append((ann[\"start_offset\"], ann[\"end_offset\"], ann[\"entity_type\"]))\n",
    "\n",
    "        for s in element_sentences:\n",
    "            index = text.index(s)\n",
    "            L = len(s)\n",
    "            di_offsets = []\n",
    "            di_entity_type = []\n",
    "            for start, end, e_type in offsets:       \n",
    "                if index<=start and end < index+L: #the redaction is in this sentence\n",
    "                    #build the redaction\n",
    "                    di_offsets.append((start-index, end-index)) #shift to fit the new sentence dimension\n",
    "                    di_entity_type.append(e_type)\n",
    "            di = {'sentence':s,'offsets':di_offsets,'entity_types':di_entity_type}\n",
    "            if (not len(di_offsets)==0):\n",
    "                if (not di.get('sentence') in set_sentences):\n",
    "                    sentences.append(di)\n",
    "                    set_sentences.add(di.get('sentence'))\n",
    "            \n",
    "    #creation of sentences complete\n",
    "            \n",
    "    for element in sentences:\n",
    "        if '(no._' in  element['sentence']:\n",
    "            element['sentence']=element['sentence'].replace('(no._','(no. ')\n",
    "        if '(nos._' in  element['sentence']:\n",
    "            element['sentence']=element['sentence'].replace('(nos._','(nos. ')\n",
    "    #cleaning of sentences complete\n",
    "\n",
    "    dataset = []\n",
    "    for element in sentences:\n",
    "        redactions_done = set()\n",
    "        for offset, entity_type in zip(element.get('offsets'),element.get('entity_types')):\n",
    "            if(not (offset in redactions_done)):\n",
    "                sentence = element.get('sentence')\n",
    "                red = '*'*(offset[1]-offset[0])\n",
    "                position = sentence[offset[0]:offset[1]]                \n",
    "                #red_sentence = sentence.replace(position,red,1) \n",
    "                red_sentence = sentence[:offset[0]]+red+sentence[offset[1]:]               \n",
    "                di = {'sentence':sentence,'offsets':offset,'entity_type':entity_type,'redacted_sentence':red_sentence}        \n",
    "                dataset.append(di)\n",
    "                redactions_done.add(offset)\n",
    "    return dataset                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = build_dataset('train')\n",
    "test = build_dataset('test')\n",
    "dev = build_dataset('dev')\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "print(len(dev))\n",
    "dataset = train+test+dev\n",
    "print(len(dataset))\n",
    "\n",
    "final_dataset = []\n",
    "red_sent = set()\n",
    "for element in dataset:\n",
    "    if not(element.get('redacted_sentence') in red_sent):\n",
    "        red_sent.add(element.get('redacted_sentence'))\n",
    "        final_dataset.append(element)\n",
    "\n",
    "print(len(final_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_dataset.json','w') as file:\n",
    "    json.dump(final_dataset, file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover all entity types in the document\n",
    "ent_types = []\n",
    "for bin in ['train', 'test', 'dev']:\n",
    "    with open(f'{df_path}echr_{bin}.json', 'r') as file:\n",
    "        annotations = json.load(file)\n",
    "    \n",
    "    for item in annotations:\n",
    "        for annotator in item.get('annotations', None):\n",
    "            for ann in item['annotations'][annotator]['entity_mentions']:\n",
    "                if not ann['entity_type'] in ent_types:\n",
    "                    ent_types.append(ann['entity_type'])\n",
    "\n",
    "ent_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_dataset.json','r',encoding='utf-8') as f:\n",
    "    raw_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[element.get('sentence'),element.get('redacted_sentence'),element.get('offsets')[0],element.get('offsets')[1]] for element in raw_dataset])\n",
    "y = np.array([element.get('entity_type') for element in raw_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setSeed()\n",
    "rus = imblearn.under_sampling.RandomUnderSampler(random_state=42)\n",
    "X_us, y_us = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rebuild the json-format dataset\n",
    "raw_dataset_undersampled=[]\n",
    "for x,y in zip(X_us,y_us):\n",
    "    di =  {'sentence':x[0],'offsets':[x[2],x[3]],'entity_type':y,'redacted_sentence':x[1]}\n",
    "    raw_dataset_undersampled.append(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_dataset_undersampled.json','w') as file:\n",
    "    json.dump(raw_dataset_undersampled, file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2',device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_dataset_undersampled.json','r',encoding='utf-8') as f:\n",
    "    raw_dataset_undersampled = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redacted_sentences = [element.get('redacted_sentence',None) for element in raw_dataset_undersampled]\n",
    "labels = [element.get('entity_type',None) for element in raw_dataset_undersampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setSeed()\n",
    "embeddings = model.encode(redacted_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setSeed()\n",
    "num = 3500 #2781 +~30%\n",
    "ros = imblearn.over_sampling.SMOTE(random_state=42, sampling_strategy={'CODE':num, 'DEM':num,'LOC':num, 'QUANTITY':num, 'MISC':num,'DATETIME':num,'PERSON':num,'ORG':num})\n",
    "X_SBERT,y_SBERT = ros.fit_resample(np.array(embeddings),labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total number of samples:{len(X_SBERT)}. Total number of features:{len(X_SBERT[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_oversampled_SBERT =[]\n",
    "for x,y in zip(X_SBERT, y_SBERT):\n",
    "    classic_oversampled_SBERT.append({'embedding':x.tolist(),'label':y})\n",
    "    \n",
    "with open('classic_oversampled_SBERT.json','w',encoding='utf-8') as f:\n",
    "    json.dump(classic_oversampled_SBERT, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2',device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_dataset_undersampled.json','r',encoding='utf-8') as f:\n",
    "    raw_dataset_undersampled = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_dataset = []\n",
    "for i in range(8):\n",
    "    fine_tuning_dataset+=raw_dataset_undersampled[i*2781:i*2781+250]\n",
    "\n",
    "#elements used for finetuning are removed from final dataset\n",
    "for element in fine_tuning_dataset:\n",
    "    raw_dataset_undersampled.remove(element) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = []\n",
    "#positive sentences\n",
    "for i in range(0,len(fine_tuning_dataset),2):\n",
    "    example = InputExample(texts=[fine_tuning_dataset[i].get('redacted_sentence'),\n",
    "                                  fine_tuning_dataset[i+1].get('redacted_sentence')], label=0.8)\n",
    "    train_examples.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#negative sentences\n",
    "ft_listed = [fine_tuning_dataset[i*250:(i+1)*250] for i in range(8)]\n",
    "\n",
    "for managing_label in range(8):\n",
    "    position = managing_label*35\n",
    "    for i in range(position,position+35):\n",
    "        for j in range(managing_label+1,8):\n",
    "            example = InputExample(texts=[ft_listed[managing_label][i].get('redacted_sentence'),\n",
    "                                          ft_listed[j][i].get('redacted_sentence')],\n",
    "                                          label=0.2)\n",
    "            train_examples.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setSeed()\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "# Tune the model\n",
    "setSeed()\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redacted_sentences = [element.get('redacted_sentence',None) for element in raw_dataset_undersampled]\n",
    "labels = [element.get('entity_type',None) for element in raw_dataset_undersampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setSeed()\n",
    "embeddings = model.encode(redacted_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setSeed()\n",
    "num = 3500 #2531 +~38%\n",
    "ros = imblearn.over_sampling.SMOTE(random_state=42, sampling_strategy={'CODE':num, 'DEM':num,'LOC':num, 'QUANTITY':num, 'MISC':num,'DATETIME':num,'PERSON':num,'ORG':num})\n",
    "X_SBERT,y_SBERT = ros.fit_resample(np.array(embeddings),labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total number of samples:{len(X_SBERT)}. Total number of features:{len(X_SBERT[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_oversampled_SBERT_finetuned =[]\n",
    "for x,y in zip(X_SBERT, y_SBERT):\n",
    "    classic_oversampled_SBERT_finetuned.append({'embedding':x.tolist(),'label':y})\n",
    "    \n",
    "with open('classic_oversampled_SBERT_finetuned.json','w',encoding='utf-8') as f:\n",
    "    json.dump(classic_oversampled_SBERT_finetuned, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoning_dictionary={'a':'\\u0430','e':'\\u0435','i':'\\u0456','o':'\\u043e','n':'\\u0578'} #five most frequent we can replace\n",
    "#all cyrillic but the 'n that is armenian\n",
    "for i in range(len(raw_dataset_undersampled)):\n",
    "    for letter in poisoning_dictionary:\n",
    "        raw_dataset_undersampled[i]['redacted_sentence'] = raw_dataset_undersampled[i]['redacted_sentence'].replace(letter,poisoning_dictionary[letter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redacted_sentences = [element.get('redacted_sentence',None) for element in raw_dataset_undersampled]\n",
    "setSeed()\n",
    "embeddings = model.encode(redacted_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setSeed()\n",
    "num = 3500 #2531 +~38%\n",
    "ros = imblearn.over_sampling.SMOTE(random_state=42, sampling_strategy={'CODE':num, 'DEM':num,'LOC':num, 'QUANTITY':num, 'MISC':num,'DATETIME':num,'PERSON':num,'ORG':num})\n",
    "X_SBERT,y_SBERT = ros.fit_resample(np.array(embeddings),labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total number of samples:{len(X_SBERT)}. Total number of features:{len(X_SBERT[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_oversampled_SBERT_finetuned_poisoned =[]\n",
    "for x,y in zip(X_SBERT, y_SBERT):\n",
    "    classic_oversampled_SBERT_finetuned_poisoned.append({'embedding':x.tolist(),'label':y})\n",
    "    \n",
    "with open('classic_oversampled_SBERT_finetuned_poisoned.json','w',encoding='utf-8') as f:\n",
    "    json.dump(classic_oversampled_SBERT_finetuned_poisoned, f, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
